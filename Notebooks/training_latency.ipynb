{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import GPUtil\n",
    "import tensorflow as tf\n",
    "\n",
    "relative_path = '../'\n",
    "sys.path.append(relative_path)\n",
    "\n",
    "from LatentCA.model import NAFCA\n",
    "from LatentCA.trainer import LatentTrainerWrapper\n",
    "from NAFNet.trainer import TrainerNAFNet\n",
    "from Restormer.trainer import TrainerRestormer\n",
    "from Utils.generic_utils import get_reduced_name_list\n",
    "from Utils.trainer_utils import DataGenerator, TestLauncher, create_dummy_dataset, get_elapsed_time\n",
    "from ViTCA.model import ViTCA\n",
    "from ViTCA.trainer import TrainerViTCA\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "img_shape = (32, 32, 32, 3)\n",
    "num_iterations = 3\n",
    "model_names = ['nafnet', 'restormer', 'vitca', 'latentvitca', 'latentnafca']\n",
    "model = model_names[4]\n",
    "save_df = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset does not exist, creating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:00<00:00, 2205.05it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_directory = relative_path + 'Datasets/Dummy_{}_{}_{}_{}/'.format(*img_shape)\n",
    "if not os.path.exists(dataset_directory):\n",
    "    print('Dataset does not exist, creating...')\n",
    "    os.mkdir(dataset_directory)\n",
    "    create_dummy_dataset(num_images=1250, shape=img_shape[1:], path=dataset_directory)\n",
    "else:\n",
    "    print('Dataset already existing, loading...')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Split:\n",
      "Train: 800\n",
      "Validation: 200\n",
      "Test: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 5414.10it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 5427.90it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 5986.01it/s]\n"
     ]
    }
   ],
   "source": [
    "reduction = 1.\n",
    "test_split = 0.8\n",
    "val_split = 0.8\n",
    "curriculum_learning = True\n",
    "task_dict = {'task': 'Noise', 'range': 1., 'intensity': 0.5, 'a_min': 0.25, 'a_max': 0.75}\n",
    "real_dataset = False\n",
    "train, val, test = get_reduced_name_list(path=dataset_directory, reduction=reduction, test_split=test_split,\n",
    "                                         val_split=val_split, real_dataset=real_dataset)\n",
    "train_gen = DataGenerator(directory=dataset_directory, filenames=train, img_size=img_shape,\n",
    "                          task_info=copy.deepcopy(task_dict), train_ca=True, shuffle=True,\n",
    "                          num_iterations=num_iterations, curriculum=curriculum_learning, train=True,\n",
    "                          real_dataset=real_dataset)\n",
    "val_gen = DataGenerator(directory=dataset_directory, filenames=val, img_size=img_shape,\n",
    "                        task_info=copy.deepcopy(task_dict), train_ca=True, shuffle=False,\n",
    "                        num_iterations=num_iterations, curriculum=False, train=False, real_dataset=real_dataset)\n",
    "test_gen = DataGenerator(directory=dataset_directory, filenames=test, img_size=img_shape,\n",
    "                         task_info=copy.deepcopy(task_dict), train_ca=True, shuffle=False,\n",
    "                         num_iterations=num_iterations, curriculum=False, train=False, real_dataset=real_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "common_params = {\n",
    "    'base_dir': relative_path + 'Results/',\n",
    "    'dataset': dataset_directory.split('/')[-2],\n",
    "    'task': task_dict['task'],\n",
    "    'epochs': num_iterations,\n",
    "    'train': train_gen,\n",
    "    'val': val_gen,\n",
    "    'test': test_gen,\n",
    "    'monitor_metric': 'SSIM',\n",
    "    'display_frequency': num_iterations + 1,\n",
    "    'test_length': 4,\n",
    "    'model_params_dicts': None,\n",
    "    'telegram_token': None,\n",
    "    'telegram_chat_id': None\n",
    "}\n",
    "\n",
    "max_depth = 16\n",
    "num_down_sampling = 2\n",
    "cell_in_channels = cell_out_channels = max_depth\n",
    "cell_hidden_channels = 32\n",
    "pool_shape = (img_shape[0], img_shape[1] // (2 ** num_down_sampling), img_shape[1] // (2 ** num_down_sampling),\n",
    "              cell_in_channels + cell_out_channels + cell_hidden_channels)\n",
    "latent_shape = (img_shape[1] // (2 ** num_down_sampling), img_shape[1] // (2 ** num_down_sampling), max_depth)\n",
    "latent_params = {\n",
    "    'model_params': {\n",
    "        'input_shape': img_shape,\n",
    "        'pool_shape': pool_shape,\n",
    "        'latent_shape': latent_shape,\n",
    "        'CAParams': None,\n",
    "        'Conv2DParams1': {\n",
    "            'filters': max_depth // 2,\n",
    "            'kernel_size': (3, 3),\n",
    "            'strides': (2, 2),\n",
    "            'padding': 'same',\n",
    "            'activation': 'swish',\n",
    "            'batch_normalization': True,\n",
    "            'dropout_rate': 0.0\n",
    "        },\n",
    "        'Conv2DParams2': {\n",
    "            'filters': max_depth,\n",
    "            'kernel_size': (3, 3),\n",
    "            'strides': (2, 2),\n",
    "            'padding': 'same',\n",
    "            'activation': 'swish',\n",
    "            'batch_normalization': True,\n",
    "            'dropout_rate': 0.0\n",
    "        },\n",
    "        'PassThroughParams1': {\n",
    "            'filters': max_depth // 2,\n",
    "            'kernel_size': (3, 3),\n",
    "            'strides': (2, 2),\n",
    "            'padding': 'same',\n",
    "            'activation': 'swish',\n",
    "            'batch_normalization': True,\n",
    "            'dropout_rate': 0.0\n",
    "        },\n",
    "        'Conv2DTransposeParams2': {\n",
    "            'filters': max_depth // 2,\n",
    "            'kernel_size': (3, 3),\n",
    "            'strides': (2, 2),\n",
    "            'padding': 'same',\n",
    "            'activation': 'swish',\n",
    "            'batch_normalization': True,\n",
    "            'dropout_rate': 0.0\n",
    "        },\n",
    "        'MixParams': {\n",
    "            'filters': max_depth // 2,\n",
    "            'kernel_size': (3, 3),\n",
    "            'strides': (1, 1),\n",
    "            'padding': 'same',\n",
    "            'activation': 'swish',\n",
    "            'batch_normalization': True,\n",
    "            'dropout_rate': 0.0\n",
    "        },\n",
    "        'Conv2DTransposeParams1': {\n",
    "            'filters': 3,\n",
    "            'kernel_size': (3, 3),\n",
    "            'strides': (2, 2),\n",
    "            'padding': 'same',\n",
    "            'activation': 'sigmoid',\n",
    "            'batch_normalization': True,\n",
    "            'dropout_rate': 0.0\n",
    "        }},\n",
    "    'trainer': LatentTrainerWrapper,\n",
    "    'learning_rate': 1e-2,\n",
    "    'num_down_sampling': num_down_sampling,\n",
    "    'margin': 1.,\n",
    "    'reconstruction_loss_ae': 'MSE',\n",
    "    'reconstruction_loss_weight_ae': 100,\n",
    "    'distance_loss': 'MSE',\n",
    "    'distance_loss_weight': 10,\n",
    "    'task_loss': 'MSE',  # PSNR\n",
    "    'task_loss_weight': 10,\n",
    "    'equivalent_loss': 'PureNoiseMSE',\n",
    "    'equivalent_loss_weight': 100,\n",
    "    'perturbation_intensity': 0.5,\n",
    "    'total_variation_loss_ae': False,\n",
    "    'total_variation_loss_weight_ae': 1,\n",
    "    'reconstruction_loss': 'MSE',\n",
    "    'reconstruction_loss_weight': 100,\n",
    "    'latent_loss': 'MSE',\n",
    "    'latent_loss_weight': 100,\n",
    "    'output_overflow_loss': True,\n",
    "    'output_overflow_loss_weight': 1,\n",
    "    'hidden_overflow_loss': True,\n",
    "    'hidden_overflow_loss_weight': 1,\n",
    "    'total_variation_loss': False,\n",
    "    'total_variation_loss_weight': 1,\n",
    "    'update_probability': 1.,\n",
    "    'min_cell_updates': 8,\n",
    "    'max_cell_updates': 32,\n",
    "    'pool_length': 1024\n",
    "}\n",
    "latent_nafca_params = {\n",
    "    'class': NAFCA,\n",
    "    'localized_attention_neighbourhood': (3, 3),\n",
    "    'ffn_expand': 4,\n",
    "    'dropout': 0.1,\n",
    "    'embed_dim': 128,\n",
    "    'cell_in_channels': cell_in_channels,\n",
    "    'cell_out_channels': cell_out_channels,\n",
    "    'cell_hidden_channels': cell_hidden_channels\n",
    "}\n",
    "latent_vitca_params = {\n",
    "    'class': ViTCA,\n",
    "    'localized_attention_neighbourhood': (3, 3),\n",
    "    'patch_size': 1,\n",
    "    'pos_encoding_max_freq': 5,\n",
    "    'depth': 1,\n",
    "    'heads': 4,\n",
    "    'mlp_dim': 64,\n",
    "    'dropout': 0.0,\n",
    "    'embed_cells': True,\n",
    "    'embed_dim': 128,\n",
    "    'embed_dropout': 0.0,\n",
    "    'pool_shape': pool_shape,\n",
    "    'cell_in_channels': cell_in_channels,\n",
    "    'cell_out_channels': cell_out_channels,\n",
    "    'cell_hidden_channels': cell_hidden_channels\n",
    "}\n",
    "nafnet_params = {\n",
    "    'model_name': 'NAFNet',\n",
    "    'trainer': TrainerNAFNet,\n",
    "    'model_params': {\n",
    "        'input_shape': img_shape,\n",
    "        'width': 64,\n",
    "        'enc_block_nums': [2, 2, 4, 8],\n",
    "        'middle_block_num': 12,\n",
    "        'dec_block_nums': [2, 2, 2, 2]},\n",
    "    'learning_rate': 1e-3\n",
    "}\n",
    "restormer_params = {\n",
    "    'model_name': 'Restormer',\n",
    "    'trainer': TrainerRestormer,\n",
    "    'model_params': {\n",
    "        'input_shape': img_shape,\n",
    "        'out_channels': 3,\n",
    "        'dim': 48,\n",
    "        'num_blocks': [4, 6, 6, 8],\n",
    "        'num_refinement_blocks': 4,\n",
    "        'heads': [1, 2, 4, 8],\n",
    "        'ffn_expansion_factor': 2.66,\n",
    "        'bias': False},\n",
    "    'learning_rate': 3e-4,\n",
    "}\n",
    "vitca_params = {\n",
    "    'model_name': 'ViTCA',\n",
    "    'trainer': TrainerViTCA,\n",
    "    'model_params': {\n",
    "        'input_shape': img_shape,\n",
    "        'localized_attention_neighbourhood': [3, 3],\n",
    "        'patch_size': 1,\n",
    "        'overlapping_patches': False,\n",
    "        'pos_encoding_method': 'vit_handcrafted',\n",
    "        'pos_encoding_basis': 'raw_xy',\n",
    "        'pos_encoding_max_freq': 5,\n",
    "        'depth': 1,\n",
    "        'heads': 4,\n",
    "        'mlp_dim': 64,\n",
    "        'dropout': 0.0,\n",
    "        'cell_init': 'constant',\n",
    "        'cell_in_channels': img_shape[-1],\n",
    "        'cell_out_channels': img_shape[-1],\n",
    "        'cell_hidden_channels': cell_hidden_channels,\n",
    "        'embed_cells': True,\n",
    "        'embed_dim': 128,\n",
    "        'embed_dropout': 0.0},\n",
    "    'learning_rate': 1e-3,\n",
    "    'output_overflow_loss': True,\n",
    "    'hidden_overflow_loss': True,\n",
    "    'reconstruction_loss_factor': 1e2,\n",
    "    'overflow_loss_factor': 1e2,\n",
    "    'pool_length': 1024,\n",
    "    'update_probability': 0.5,\n",
    "    'min_cell_updates': 8,\n",
    "    'max_cell_updates': 32,\n",
    "}\n",
    "latent_nafca_params_complete = copy.deepcopy(latent_params)\n",
    "latent_nafca_params_complete['model_params']['CAParams'] = latent_nafca_params\n",
    "latent_nafca_params_complete['model_name'] = 'LatentNAFCA'\n",
    "latent_vitca_params_complete = copy.deepcopy(latent_params)\n",
    "latent_vitca_params_complete['model_params']['CAParams'] = latent_vitca_params\n",
    "latent_vitca_params_complete['model_name'] = 'LatentViTCA'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "latent_model = False\n",
    "if model == nafnet_params['model_name'].lower():\n",
    "    common_params['model_params_dicts'] = [nafnet_params]\n",
    "elif model == restormer_params['model_name'].lower():\n",
    "    common_params['model_params_dicts'] = [restormer_params]\n",
    "elif model == vitca_params['model_name'].lower():\n",
    "    common_params['model_params_dicts'] = [vitca_params]\n",
    "elif model == latent_vitca_params_complete['model_name'].lower():\n",
    "    common_params['model_params_dicts'] = [latent_vitca_params_complete]\n",
    "    latent_model = True\n",
    "else:\n",
    "    common_params['model_params_dicts'] = [latent_nafca_params_complete]\n",
    "    latent_model = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial free GPU VRAM: 11181.00 MB\n"
     ]
    }
   ],
   "source": [
    "gpus = GPUtil.getGPUs()\n",
    "vram_before = gpus[0].memoryFree\n",
    "print('Initial free GPU VRAM: {:.2f} MB'.format(vram_before))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start LatentNAFCA's Training...\n",
      "1/3 epoch - 24/24 batch - train_rec_loss: 0.073 - train_dist_loss: 0.082 - train_task_loss: 0.021 - train_equiv_loss: 0.041 - train_PSNR: 11.438 - train_SSIM: 0.324 || val_rec_loss: 0.074 - val_dist_loss: 0.878 - val_task_loss: 0.043 - val_equiv_loss: 0.081 - val_PSNR: 11.298 - val_SSIM: 0.170\n",
      " || elapsed_time: 13.846\n",
      "Found new Best, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _draw_all_if_interactive at 0x0000029662C42DD0> (for post_execute):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x000002979A82BB50> (for post_execute):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "launcher = TestLauncher(common_params)\n",
    "launcher.launch()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gpus = GPUtil.getGPUs()\n",
    "vram_used = vram_before - gpus[0].memoryFree\n",
    "print('Maximum GPU VRAM usage: {:.2f} MB'.format(vram_used))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = get_elapsed_time(base_dir=os.path.join(common_params['base_dir'], common_params['task'],common_params['dataset']),\n",
    "                      model_name=common_params['model_params_dicts'][0]['model_name'], latent=latent_model)\n",
    "if save_df:\n",
    "    df.to_pickle('training_latency-{}-{}-{}.pkl'.format(model, img_shape, num_iterations))\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Mean elapsed time: {:.2f} s'.format(df.mean()))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
